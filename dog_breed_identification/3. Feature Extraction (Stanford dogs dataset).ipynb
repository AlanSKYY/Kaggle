{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Feature Extraction (Stanford dogs dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running, please visit [Stanford dogs dataset](http://vision.stanford.edu/aditya86/ImageNetDogs/) and download [images.tar](http://vision.stanford.edu/aditya86/ImageNetDogs/images.tar). Create a folder named \"data\" in the directory storing this Python notebook (if you haven't done so in step 1) and unzip the content inside \"data\" folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import init, gluon, nd, autograd, image\n",
    "from mxnet.gluon import nn\n",
    "from mxnet.gluon.data import vision\n",
    "from mxnet.gluon.model_zoo import vision as models\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import h5py\n",
    "import os\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# Change the following to mx.cpu() if you don't have GPU in your computer.\n",
    "# To use different GPU, you can try \"ctx = mx.gpu(1)\", where 1 is the first GPU.\n",
    "ctx = mx.gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data\" \n",
    "\n",
    "#288 = 224 + 32 *2, 352 = 224 + 32 * 4\n",
    "imageSize_resnet = 288  \n",
    "\n",
    "# 363 = 299 + 32 *2, 427 = 299 + 32 * 4\n",
    "imageSize_inception = 363"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, labels):\n",
    "    return nd.mean(nd.argmax(output, axis=1) == labels).asscalar()\n",
    "\n",
    "\n",
    "def evaluate(net, data_iter):\n",
    "    loss, acc, n = 0., 0., 0.\n",
    "    steps = len(data_iter)\n",
    "    for data, label in data_iter:\n",
    "        data, label = data.as_in_context(ctx), label.as_in_context(ctx)\n",
    "        output = net(data)\n",
    "        acc += accuracy(output, label)\n",
    "        loss += nd.mean(softmax_cross_entropy(output, label)).asscalar()\n",
    "    return loss/steps, acc/steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(glob(os.path.join('.', data_dir, \"Images\", \"*\", \"*.jpg\")))\n",
    "\n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 161/161 [12:27<00:00,  9.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20580, 2048)\n",
      "CPU times: user 10min 32s, sys: 2min 9s, total: 12min 41s\n",
      "Wall time: 12min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "net = models.get_model('resnet152_v1', pretrained=True, ctx=ctx)\n",
    "features = []\n",
    "for j in tqdm(range(0,161)):\n",
    "    i = 0\n",
    "    temp = nd.zeros((128, 3, imageSize_resnet, imageSize_resnet)) \n",
    "    for file_name in glob(os.path.join(data_dir, \"Images\", \"*\", \"*.jpg\"))[128*j:128*(j+1)]:\n",
    "        img = cv2.imread(file_name)\n",
    "        img_224 = ((cv2.resize(img, (imageSize_resnet, imageSize_resnet))[:,:,::-1] \\\n",
    "                    / 255.0 - mean) / std).transpose((2, 0, 1))\n",
    "        temp[i] = nd.array(img_224)\n",
    "        nd.waitall()\n",
    "        i += 1\n",
    "    if j == 160:\n",
    "        temp = temp[0:100]\n",
    "    data_iter_224 = gluon.data.DataLoader(gluon.data.ArrayDataset(temp), batch_size=128)\n",
    "    for data in data_iter_224:\n",
    "        feature = net.features(data.as_in_context(mx.gpu()))\n",
    "        feature = gluon.nn.Flatten()(feature)\n",
    "        features.append(feature.as_in_context(mx.cpu()))\n",
    "    nd.waitall()\n",
    "features = nd.concat(*features, dim=0)\n",
    "print(features.shape)\n",
    "nd.save(os.path.join(data_dir, 'features_res.nd'), features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 161/161 [12:17<00:00, 15.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20580, 2048)\n",
      "CPU times: user 8min 55s, sys: 4min 34s, total: 13min 30s\n",
      "Wall time: 12min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "net = models.get_model('inceptionv3', pretrained=True, ctx=ctx)\n",
    "features = []\n",
    "for j in tqdm(range(0,161)):\n",
    "    i = 0\n",
    "    temp = nd.zeros((128, 3, imageSize_inception, imageSize_inception)) \n",
    "    for file_name in glob(os.path.join(data_dir, \"Images\", \"*\", \"*.jpg\"))[128*j:128*(j+1)]:\n",
    "        img = cv2.imread(file_name)\n",
    "        img_299 = ((cv2.resize(img, (imageSize_inception, imageSize_inception))[:,:,::-1] \\\n",
    "                    / 255.0 - mean) / std).transpose((2, 0, 1))\n",
    "        temp[i] = nd.array(img_299)\n",
    "        nd.waitall()\n",
    "        i += 1\n",
    "    if j == 160:\n",
    "        temp = temp[0:100]\n",
    "    data_iter_299 = gluon.data.DataLoader(gluon.data.ArrayDataset(temp), batch_size=128)\n",
    "    for data in data_iter_299:\n",
    "        feature = net.features(data.as_in_context(mx.gpu()))\n",
    "        feature = gluon.nn.Flatten()(feature)\n",
    "        features.append(feature.as_in_context(mx.cpu()))\n",
    "    nd.waitall()\n",
    "features = nd.concat(*features, dim=0)\n",
    "print(features.shape)\n",
    "nd.save(os.path.join(data_dir, 'features_incep.nd'), features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
